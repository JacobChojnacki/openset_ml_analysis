{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51004f7d",
   "metadata": {},
   "source": [
    "# Metody detekcji anomalii - laboratorium\n",
    "\n",
    "* W pierwszej części laboratorium poznamy metody wyznaczania anomalii w danych (anomaly detection) oraz techniki badania czy nowe dane pochodzą ze znanego rozkładu (novelty/out-of-distribution (OOD) detection). \n",
    "\n",
    "* W drugiej części zastosujemy te techniki do reprezentacji generowanych przez głębokie sieci neuronowe. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15bd17",
   "metadata": {},
   "source": [
    "## Zadanie\n",
    "\n",
    "Zadanie polega na zbadaniu różnych metod wykrywania anomalii - zilustrowanych w tej instrukcji (notebooku) do wykrywania anomalii w rzeczywistych zbiorach danych. \n",
    "\n",
    "Przykładową analizę dla danych rzeczywistych pokazujemy w notebooku **02_real_data.ipynb**.\n",
    "\n",
    "Przebieg zadania:\n",
    "\n",
    "**1. Wybieramy 3 zbiory danych** z repozytorium na stronie http://odds.cs.stonybrook.edu/. Wybieramy zbiory o różnych charakterystykach (wymiarowość, liczba outlierów).\n",
    "\n",
    "**2. Dla każdego zbioru** badamy skuteczność wykrywania anomalii za pomocą 3 metod - np. podanych w tej instrukcji, można też użyć inne metody (np. kNN). Staramy się dostroić parametry detektora anomalii tak żeby uzyskać wysoką skuteczność metody. \n",
    "\n",
    "**3. Opracowujemy raport z badań** - powinien zawierać miary skuteczności każdej badanej metody (ROC, AUC, FPR, TPR) oraz wpływ parametrów, które poddawaliśmy strojeniu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bb949",
   "metadata": {},
   "source": [
    "## Badamy metody wyznaczania *outlierness scores* na danych symulacyjnych\n",
    "\n",
    "LOF \\\n",
    "odległość Mahalanobisa \\\n",
    "IRW depth \\\n",
    "isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57bc4b73",
   "metadata": {},
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import time\n",
    "import math\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ef605a",
   "metadata": {},
   "source": [
    "# generujemy dane MVN - dane znane (in-distribution, ID) oraz out-of-distribution (OOD) \n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "d = 10\n",
    "n = 500\n",
    "mi = np.full(d, 0)\n",
    "cov = np.identity(d)\n",
    "\n",
    "X_train = rng.multivariate_normal(mi, cov, n)\n",
    "X_test = rng.multivariate_normal(mi, cov, n)\n",
    "\n",
    "# OOD\n",
    "delta = 10\n",
    "mi2 = np.full(d, delta/math.sqrt(d))\n",
    "X_ood = rng.multivariate_normal(mi2, cov, n)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "55aed9b6",
   "metadata": {},
   "source": [
    "### IRW - Integrated Rank-Weighted depth\n",
    "\n",
    "    based on NIPS2022 paper P.Colombo et al., Beyond Mahalanobis-Based Scores for Textual OOD Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c18aa1",
   "metadata": {},
   "source": [
    "# IRW\n",
    "from openset.IRW_score import IRWdepth\n",
    "\n",
    "model = IRWdepth()\n",
    "nproj = 1000\n",
    "model.fit(X_train, nproj)\n",
    "\n",
    "start_time = time.time()\n",
    "train_scores = [model.score(row) for row in X_train]\n",
    "test_scores = [model.score(row) for row in X_test]\n",
    "ood_scores = [model.score(row) for row in X_ood]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "if 1:\n",
    "    print(np.mean(train_scores))\n",
    "    print(np.mean(test_scores)) \n",
    "\n",
    "\n",
    "# boxplot\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4), constrained_layout=True)\n",
    "\n",
    "labels = ['train', 'test', 'ood']\n",
    "#ax1.set_ylim([40, 65])\n",
    "ax1.boxplot([train_scores, test_scores, ood_scores], labels=labels)\n",
    "ax1.grid()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e5d39496",
   "metadata": {},
   "source": [
    "### LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43b05c5",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "model = LocalOutlierFactor(n_neighbors=35, novelty=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "train_scores = model.score_samples(X_train)\n",
    "test_scores = model.score_samples(X_test)\n",
    "ood_scores = model.score_samples(X_ood)\n",
    "\n",
    "\n",
    "if 1:\n",
    "    print(np.mean(train_scores))\n",
    "    print(np.mean(test_scores))\n",
    "    print(np.mean(ood_scores))\n",
    "\n",
    "\n",
    "# boxplot\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4), constrained_layout=True)\n",
    "\n",
    "labels = ['train', 'test', 'ood']\n",
    "#ax1.set_ylim([40, 65])\n",
    "ax1.boxplot([train_scores, test_scores, ood_scores], labels=labels)\n",
    "ax1.grid()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "658a969f",
   "metadata": {},
   "source": [
    "### Parametric model - assume MVN data\n",
    "    outlierness score - based on Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6400b4",
   "metadata": {},
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "model = EllipticEnvelope(contamination=0.01, random_state=42)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "train_scores = model.score_samples(X_train)\n",
    "test_scores = model.score_samples(X_test)\n",
    "ood_scores = model.score_samples(X_ood)\n",
    "\n",
    "\n",
    "if 1:\n",
    "    print(np.mean(train_scores))\n",
    "    print(np.mean(test_scores))\n",
    "    print(np.mean(ood_scores))\n",
    "\n",
    "\n",
    "# boxplot\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4), constrained_layout=True)\n",
    "\n",
    "labels = ['train', 'test', 'ood']\n",
    "#ax1.set_ylim([40, 65])\n",
    "ax1.boxplot([train_scores, test_scores, ood_scores], labels=labels)\n",
    "ax1.grid()\n",
    "\n",
    "plt.show()\n",
    "## "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "682d685c",
   "metadata": {},
   "source": [
    "# ROC curve\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_ood.shape)\n",
    "XX = np.concatenate((X_test,X_ood), axis=0)\n",
    "print(XX.shape)\n",
    "\n",
    "yy = [0]*X_test.shape[0] + [1]*X_ood.shape[0]      # 0 - ID, 1 - OOD\n",
    "\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "yy_score = -model.decision_function(XX)\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    yy_score,\n",
    "    name=\"Mahalanobis\",\n",
    "    color=\"darkorange\",\n",
    "    pos_label=1\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Mahalanobis, ROC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b7d36ca",
   "metadata": {},
   "source": [
    "### Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382ed6cf",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "model = IsolationForest(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "train_scores = model.score_samples(X_train)\n",
    "test_scores = model.score_samples(X_test)\n",
    "ood_scores = model.score_samples(X_ood)\n",
    "\n",
    "\n",
    "if 1:\n",
    "    print(np.mean(train_scores))\n",
    "    print(np.mean(test_scores))\n",
    "    print(np.mean(ood_scores))\n",
    "\n",
    "\n",
    "# boxplot\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4), constrained_layout=True)\n",
    "\n",
    "labels = ['train', 'test', 'ood']\n",
    "#ax1.set_ylim([40, 65])\n",
    "ax1.boxplot([train_scores, test_scores, ood_scores], labels=labels)\n",
    "ax1.grid()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee312656",
   "metadata": {},
   "source": [
    "#print(model.predict(X_test))\n",
    "#print(model.predict(X_ood))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "719633eb",
   "metadata": {},
   "source": [
    "## Problem wykrywania danych OOD w wysokich wymiarach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb24d1d3",
   "metadata": {},
   "source": [
    "# generujemy dane MVN - dane znane (in-distribution, ID) oraz out-of-distribution (OOD) \n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "d = 500\n",
    "n = 2000\n",
    "mi = np.full(d, 0)\n",
    "cov = np.identity(d)\n",
    "\n",
    "X_train = rng.multivariate_normal(mi, cov, n)\n",
    "X_test = rng.multivariate_normal(mi, cov, n)\n",
    "\n",
    "# OOD\n",
    "delta = 10\n",
    "mi2 = np.full(d, delta/math.sqrt(d))\n",
    "X_ood = rng.multivariate_normal(mi2, cov, n) \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f576bda6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "model = EllipticEnvelope(contamination=0.01, random_state=42)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "train_scores = model.score_samples(X_train)\n",
    "test_scores = model.score_samples(X_test)\n",
    "ood_scores = model.score_samples(X_ood)\n",
    "\n",
    "\n",
    "if 1:\n",
    "    print(np.mean(train_scores))\n",
    "    print(np.mean(test_scores))\n",
    "    print(np.mean(ood_scores))\n",
    "\n",
    "\n",
    "# boxplot\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4), constrained_layout=True)\n",
    "\n",
    "labels = ['train', 'test', 'ood']\n",
    "#ax1.set_ylim([40, 65])\n",
    "ax1.boxplot([train_scores, test_scores, ood_scores], labels=labels)\n",
    "ax1.grid()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65859c57",
   "metadata": {},
   "source": [
    "print(X_test.shape)\n",
    "print(X_ood.shape)\n",
    "XX = np.concatenate((X_test,X_ood), axis=0)\n",
    "print(XX.shape)\n",
    "\n",
    "yy = [0]*X_test.shape[0] + [1]*X_ood.shape[0]      # 0 - ID, 1 - OOD\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c178ff",
   "metadata": {},
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "yy_score = -model.decision_function(XX)\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    yy_score,\n",
    "    name=\"Mahalanobis\",\n",
    "    color=\"darkorange\",\n",
    "    pos_label=1\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Mahalanobis, ROC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
